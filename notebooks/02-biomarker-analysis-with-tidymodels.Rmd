---
title: "Biomarker Analysis with Tidymodels"
author: "Geovanny Risco"
date: '2023-02-13'
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
    df_print: paged
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Biomarker Analysis with Tidymodels

## Import libraries

```{r, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(vip)
```

## Read and prepare data


```{r}
# Read CSV from URL
cachexia_data <- read_csv("https://www.xialab.ca/api/download/metaboanalyst/human_cachexia.csv")
head(cachexia_data)
```

```{r}
# Small cleaning of data
cachexia_data <- cachexia_data %>% 
                 select(-`Patient ID`) %>% 
                 mutate(`Muscle loss`= factor(`Muscle loss`))

# Set fixed seed to achieve reproducible results
set.seed(448)

# Split data into training and testing data
splits      <- initial_split(cachexia_data, strata = `Muscle loss`)
cachexia_train <- training(splits)
cachexia_test  <- testing(splits)
```


## Setup model


```{r}
# Set up recipe
rec <- recipe(`Muscle loss` ~ ., data = cachexia_train) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())

# Set up random forest model using parsnip. 
# We use `tune()` function for the params `mtry` (number of predictors at each node) and `min_n` (minimum number of data points required to keep splitting)
rf_spec <- rand_forest(mtry = tune(), min_n = tune(), trees = 500) %>%
  set_engine("ranger", num.threads = parallel::detectCores()) %>%
  set_mode("classification")

extract_parameter_set_dials(rf_spec)
```

## Tune hyperparameters

```{r}
# Set up workflow with random forest model
rf_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf_spec)

# Space-filling design to tune, with 25 candidate models
cachexia_train_rs <- bootstraps(cachexia_train, times = 30)
rf_res <- 
  rf_wf %>% 
  tune_grid(cachexia_train_rs,
            grid = 15,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

# Show top 5 models based on ROC AUC
rf_res %>% 
  show_best(metric = "roc_auc")
```
## Extract feature importances from best model

```{r}
# the last model
last_rf_mod <- 
  rand_forest(mtry = 5, min_n = 35, trees = 500) %>% 
  set_engine("ranger", num.threads = parallel::detectCores(), importance = "impurity") %>% 
  set_mode("classification")

# the last workflow
last_rf_wf <- 
  rf_wf %>% 
  update_model(last_rf_mod)

# the last fit
last_rf_fit <- 
  last_rf_wf %>% 
  last_fit(splits)

```

```{r}
# Bar plot with the feature importances
last_rf_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)

# Save the values for later
feature_importances <- last_rf_fit %>% 
  extract_fit_parsnip() %>% 
  vi()
write_csv(feature_importances, "feature_importances.csv")
```


```{r}
last_rf_fit %>% 
  collect_predictions() %>% 
  roc_curve(`Muscle loss`, .pred_cachexic) %>% 
  autoplot()
  
```

## Compare ROC curves

We will use the feature importance obtained in the previous step to create various models:

* Model with top 3 features
* Model with top 5 features
* Model with top 10 features
* Model with 3/5 the number of total features
* Model with all the features

For this, we will implement a helper function to ease this process:

```{r}
compute_roc_curve <- function(data, class_feature, relevant_class, recipe_formula, training_proportion) {
  # Data splitting
  splits      <- initial_split(data, strata = class_feature, prop = training_proportion)
  train_data <- training(splits)
  test_data  <- testing(splits)
  
  # Set up recipe
  rec <- recipe(recipe_formula, data = train_data) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors())

  #TODO: tune hyperparameters and select best params
  
  rf_spec <-  rand_forest(min_n = 35, trees = 500) %>% 
  # Set up random forest model
    set_engine("ranger", num.threads = parallel::detectCores()) %>% 
    set_mode("classification")

  # Set up workflow with random forest model
  rf_wf <- workflow() %>%
    add_recipe(rec) %>%
    add_model(rf_spec)

  # Train random forest model
  rf_fit <- rf_wf %>% 
    fit(train_data)

  # Predict
  rf_preds <- predict(rf_fit, test_data) %>% 
    bind_cols(predict(rf_fit, test_data, type = "prob")) %>% 
    bind_cols(
      test_data %>% 
        select(class_feature)
    )

  # Calculate ROC curve data
  roc_curve_data <- rf_preds %>% 
    roc_curve({{class_feature}}, paste(".pred", relevant_class, sep="_"))
  
  return(roc_curve_data)
}
```

Test the function with a simple example:


```{r}
selected_features <- c("Creatinine", "Succinate", "Tryptophan")
recipe_formula <- formula(paste("`Muscle loss` ~ ", paste(selected_features, collapse = "+"), sep=""))
compute_roc_curve(cachexia_data, 'Muscle loss', "cachexic", recipe_formula, 3/4) %>% 
  autoplot()
```


Now we will loop through the ranking of feature importance taking a subset of them each time, as previously said.


```{r}
# Read list of feature importance (if neccesary)
# feature_importances <- read_csv("feature_importances.csv")

# Common data for this example
data <- cachexia_data
class_feature <- 'Muscle loss'
relevant_class <- "cachexic"
training_proportion <- 3/4

# Create list to loop over
total_features <- nrow(feature_importances)
n_features_list <- c(3, 5, 10, round(1/5 * total_features), total_features)
results = vector("list", length = length(n_features_list))

# Compute roc curve data for each subset of features
for (i in 1:length(n_features_list)){
  n_features = n_features_list[[i]]
  selected_features_joined <- feature_importances %>% 
    top_n(n_features) %>% 
    .$Variable %>% 
    paste("`", ., "`", sep="", collapse="+")
  recipe_formula <- paste('`', class_feature, "` ~ ", selected_features_joined, sep="")
  print(paste("Computing ROC curve for the following formula: ", recipe_formula))
  roc_curve_data <- compute_roc_curve(data, class_feature, relevant_class, formula(recipe_formula), training_proportion)
  roc_curve_data <- roc_curve_data %>% 
    mutate(Model=paste("Top ", n_features, "features"))
  results[[i]] <- roc_curve_data
}

# Plot ROC curve for the different models
bind_rows(results) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = Model)) + 
  geom_path(linewidth = 1.0, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)

```
